---
# Slurm config (optional) -- test if this dies anything or nor
name: SLURM   # MUST BE SLURM

# Required
partition: gpu_8
job-name: Informer-Job-Traffic-Even    # this will be the experiment's name in slurm

# Required - Cluster Specific
num_parallel_jobs: 50
ntasks: 1 # leave that like it is
cpus-per-task: 2
time: 800  # Runtime in Wallclock Time. Can be int or str in form HH:MM:SS
mem-per-cpu: 4000 # Optional - Cluster specific
sbatch_args: # gpus need to be explicitly requested using this
  gres=gpu:1: "" # and this

---
# DEFAULT parameters (Optional)
name: DEFAULT   # MUST BE 'DEFAULT'

# Required: Can also be set in DEFAULT
path: /home/kit/anthropomatik/km8809/BA/BA_LTSF_w_Transformer/results # location to save results in #C:\Users\nicol\PycharmProjects\BA_LTSF_w_Transformer\results
repetitions: 1    # number of times one set of parameters is run
iterations: 100  # number of iterations per repetition

# Refer to Chapter 9 of the Docs for more info - can be set in DEFAULT
reps_per_job: 1    # number of repetitions in each job. useful for paralellization. defaults to 1.
reps_in_parallel: 1 # number of repetitions in each job that are executed in parallel. defaults to 1.

# Implementation default parameters
# Will be overwritten by named experiments.
params:
  # Basic
  is_training: 1

  # Data loader
  root_path: /home/kit/anthropomatik/km8809/BA/BA_LTSF_w_Transformer/data/UNI1 #  #C:\Users\nicol\PycharmProjects\BA_LTSF_w_Transformer\data
  features: M # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate
  target: OT # target feature in S or MS task
  freq: h # freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h
  #checkpoints: Not needed for now?
  random_seed: 4321

  # Forecasting task
  seq_len: 336 # input sequence length
  label_len: 48 # start token length
  # pred_len: 30 # prediction sequence length

  # optimization
  num_workers: 1 # data loader num workers
  batch_size: 128 # batch size of train input data
  learning_rate: 0.001 # optimizer learning rate
  des: test # exp description -- not necessary??
  loss: mse # loss function
  lradj: type3 # adjust learning rate
  pct_start: 0.3 # pct_start
  use_amp: 0
  patience: 100
  test_flop: 0

  # GPU
  use_gpu: 1
  gpu: 0 # test whether this works?
  use_multi_gpu: 0

  # Data loader
  data: Traffic_Even

list:
  data_path: [univ1_pt1_even_336_48_12_1000.pkl, univ1_pt1_even_336_48_18_1000.pkl, univ1_pt1_even_336_48_24_1000.pkl, univ1_pt1_even_336_48_30_1000.pkl]
  pred_len: [12, 18, 24, 30]


#####################################################################################################################
---
# Vanilla Transformer Experiment
name: Informer-Traffic-Even

params:
  # Basic
  model_id: Informer
  model: Informer

  # Former specific
  embed_type: 5 # 0: default 1: value embedding + temporal embedding + positional embedding 2: value embedding + temporal embedding 3: value embedding + positional embedding 4: value embedding 5: value embedding + microseconds temporal embedding
  enc_in: 1 # encoder input size
  dec_in: 1 # decoder input size
  c_out: 1 # output size
  d_model: 512 # dimension of model
  n_heads: 8 # num of heads
  e_layers: 2 # num of encoder layers
  d_layers: 1 # num of decoder layers
  d_ff: 2048 # dimension of fcn
  moving_avg: 25 # window size of moving average
  factor: 3 # attn factor
  distil: 1 # whether to use distilling in encoder, using this argument means not using distilling
  dropout: 0.05 # dropout
  embed: fixed # time features encoding, options:[timeF, fixed, learned]
  activation: gelu # activation
  output_attention: False # whether to output attention in encoder
  do_predict: False # whether to predict unseen future data

wandb:
    project: Informer-Traffic-Even-v6
    group: alr
    # sweep_id: new
    # hp_combinations_per_agent: 3 # number of trials of hyperparameter combinations. After that the job will terminate